import numpy as np 
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
my_data = pd.read_csv("drug200.csv", delimiter=",")
my_data[0:5]
# write your code here
my_data.shape
#Data Preprocessing
X = my_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values
X[0:5]
#As you may figure out, some features in this dataset are categorical such as Sex or BP. Unfortunately, 
#Sklearn Decision Trees do not handle categorical variables.But still we canconvert these features to numerical values.
#pandas.get_dummies() Convert categorical variable into dummy/indicator variables.
#Converting them into arrays

from sklearn import preprocessing
le_sex = preprocessing.LabelEncoder()
le_sex.fit(['F','M'])
X[:,1] = le_sex.transform(X[:,1]) 


le_BP = preprocessing.LabelEncoder()
le_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])
X[:,2] = le_BP.transform(X[:,2])


le_Chol = preprocessing.LabelEncoder()
le_Chol.fit([ 'NORMAL', 'HIGH'])
X[:,3] = le_Chol.transform(X[:,3]) 

X[0:5]
#Filling the target variable
y = my_data["Drug"]
y[0:5]
#We will be using train/test split on our decision tree. Let's import train_test_split from sklearn.cross_validation. 
from sklearn.model_selection import train_test_split
##Now train_test_split will return 4 different parameters. We will name them:
###X_trainset, X_testset, y_trainset, y_testset

###The train_test_split will need the parameters:
###X, y, test_size=0.3, and random_state=3.

###The X and y are the arrays required before the split, the test_size represents the ratio of the testing dataset, 
###and the random_state ensures that we obtain the same splits.
X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)
### We will do modelling Now
###Inside of the classifier, specify criterion="entropy" so we can see the information gain of each node. 
drugTree = DecisionTreeClassifier(criterion="entropy", max_depth = 4)
drugTree # it shows the default parameters
#Fitting the model
drugTree.fit(X_trainset,y_trainset)
#Prediction
predTree = drugTree.predict(X_testset)
print (predTree [0:5])
print (y_testset [0:5])
#Evaluation
from sklearn import metrics
import matplotlib.pyplot as plt
print("DecisionTrees's Accuracy: ", metrics.accuracy_score(y_testset, predTree))
###Accuracy classification score computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true. 
#Visualization
# Notice: You might need to uncomment and install the pydotplus and graphviz libraries if you have not installed these before
# !conda install -c conda-forge pydotplus -y
# !conda install -c conda-forge python-graphviz -y

from sklearn.externals.six import StringIO
import pydotplus
import matplotlib.image as mpimg
from sklearn import tree
%matplotlib inline 

dot_data = StringIO()
filename = "drugtree.png"
featureNames = my_data.columns[0:5]
targetNames = my_data["Drug"].unique().tolist()
out=tree.export_graphviz(drugTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png(filename)
img = mpimg.imread(filename)
plt.figure(figsize=(100, 200))
plt.imshow(img,interpolation='nearest')
